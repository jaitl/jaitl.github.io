<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Согласованность, Репликация и Базы Данных по CAP - Jaitl's blog</title><meta name=description content="Это ещё одна статья про CAP теорему. Я прочитал множество книг и статей по распределенным системам и в этой статье хочу обобщить полученную информацию.
В статье я рассматриваю модели согласованности данных, типы репликации данных, свойства CAP теоремы, соотношу CAP теорему с типами баз данных.
В конце я подвожу итог в котором объясняю почему CAP теорема является формальным и условным описанием распределенных систем и почему на нее не стоит полагаться."><meta name=author content="Jaitl"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Jaitl\u0027s blog","url":"https:\/\/jaitl.pro"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/jaitl.pro"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/jaitl.pro","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/jaitl.pro\/russian\/2022\/01\/25\/databases-cap\/","name":"Согласованность, репликация и базы данных по cap"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Jaitl"},"headline":"Согласованность, Репликация и Базы Данных по CAP","description":"Это ещё одна статья про CAP теорему. Я прочитал множество книг и статей по распределенным системам и в этой статье хочу обобщить полученную информацию. В статье я рассматриваю модели согласованности данных, типы репликации данных, свойства CAP теоремы, соотношу CAP теорему с типами баз данных. В конце я подвожу итог в котором объясняю почему CAP теорема является формальным и условным описанием распределенных систем и почему на нее не стоит полагаться.\n","inLanguage":"en","wordCount":2375,"datePublished":"2022-01-25T12:00:00","dateModified":"2022-01-25T12:00:00","image":"https:\/\/jaitl.pro\/img\/jaitl-avatar.png","keywords":[""],"mainEntityOfPage":"https:\/\/jaitl.pro\/russian\/2022\/01\/25\/databases-cap\/","publisher":{"@type":"Organization","name":"https:\/\/jaitl.pro","logo":{"@type":"ImageObject","url":"https:\/\/jaitl.pro\/img\/jaitl-avatar.png","height":60,"width":60}}}</script><meta property="og:title" content="Согласованность, Репликация и Базы Данных по CAP"><meta property="og:description" content="Это ещё одна статья про CAP теорему. Я прочитал множество книг и статей по распределенным системам и в этой статье хочу обобщить полученную информацию.
В статье я рассматриваю модели согласованности данных, типы репликации данных, свойства CAP теоремы, соотношу CAP теорему с типами баз данных.
В конце я подвожу итог в котором объясняю почему CAP теорема является формальным и условным описанием распределенных систем и почему на нее не стоит полагаться."><meta property="og:image" content="https://jaitl.pro/img/jaitl-avatar.png"><meta property="og:url" content="https://jaitl.pro/russian/2022/01/25/databases-cap/"><meta property="og:type" content="website"><meta property="og:site_name" content="Jaitl's blog"><meta name=twitter:title content="Согласованность, Репликация и Базы Данных по CAP"><meta name=twitter:description content="Это ещё одна статья про CAP теорему. Я прочитал множество книг и статей по распределенным системам и в этой статье хочу обобщить полученную информацию.
В статье я рассматриваю модели согласованности …"><meta name=twitter:image content="https://jaitl.pro/img/jaitl-avatar.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@jaitl"><meta name=twitter:creator content="@jaitl"><link href=https://jaitl.pro/img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.111.3"><link rel=alternate href=https://jaitl.pro/index.xml type=application/rss+xml title="Jaitl's blog"><link rel=stylesheet href=https://jaitl.pro/css/katex.min.css><link rel=stylesheet href=https://jaitl.pro/fontawesome/css/all.css><link rel=stylesheet href=https://jaitl.pro/css/bootstrap.min.css><link rel=stylesheet href=https://jaitl.pro/css/main.css><link rel=stylesheet href=https://jaitl.pro/css/fonts.css><link rel=stylesheet href=https://jaitl.pro/css/syntax.css><link rel=stylesheet href=https://jaitl.pro/css/codeblock.css><link rel=stylesheet href=https://jaitl.pro/css/photoswipe.min.css><link rel=stylesheet href=https://jaitl.pro/css/photoswipe.default-skin.min.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-KBJ7QRKR1F"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KBJ7QRKR1F",{anonymize_ip:!1})}</script></head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class=container-fluid><div class=navbar-header><button type=button class=navbar-toggle data-toggle=collapse data-target=#main-navbar>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button>
<a class=navbar-brand href=https://jaitl.pro>Jaitl's blog</a></div><div class="collapse navbar-collapse" id=main-navbar><ul class="nav navbar-nav navbar-right"><li><a title=Blog href=/>Blog</a></li><li><a title=Notes href=/notes>Notes</a></li><li><a title=Telegram href=https://t.me/seniorsITBlog>Telegram</a></li><li><a title=About href=/about>About</a></li></ul></div><div class=avatar-container><div class=avatar-img-border><a title="Jaitl's blog" href=https://jaitl.pro><img class=avatar-img src=https://jaitl.pro/img/jaitl-avatar.png alt="Jaitl's blog"></a></div></div></div></nav><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1"><div class=post-heading><h1>Согласованность, Репликация и Базы Данных по CAP</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on January 25, 2022
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;12&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;2375&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Jaitl</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>Это ещё одна статья про CAP теорему. Я прочитал множество книг и статей по распределенным системам и в этой статье хочу обобщить полученную информацию.
В статье я рассматриваю модели согласованности данных, типы репликации данных, свойства CAP теоремы, соотношу CAP теорему с типами баз данных.
В конце я подвожу итог в котором объясняю почему CAP теорема является формальным и условным описанием распределенных систем и почему на нее не стоит полагаться.</p><p>Перед тем как перейти к разбору CAP-теоремы, рассмотрим модели согласованности данных и типы репликации данных.</p><h2 id=модели-согласованности-данных>Модели согласованности данных</h2><p>Модель согласованности описывает то, как видят сохранение или изменение данных разные части распределенной системы.
Например, есть некий кластер из N нод, в котором находится таблица, в этой таблице хранится переменная <code>A=0</code>.
Есть три сервиса, которые работают с этим кластером.
Допустим, первый сервис изменил переменную на <code>A=5</code>, затем второй сервис изменил ее на <code>A=10</code>,
и после этого третий сервис считывает значение переменной <code>A</code>.
В зависимости от используемой модели согласованности данных третий сервис может считать любое из трех значений: <code>0</code>, <code>5</code>, <code>10</code>.</p><p>Существует несколько моделей согласованности данных, если вам интересна эта тема, то обратите внимание на ссылки в конце статьи.
Тут я разберу только две обобщенные модели согласованности необходимые для понимания темы.</p><h3 id=строгая-strong-consistency>Строгая (Strong consistency)</h3><p>Строгая модель предполагает, что сразу же после сохранения новых данных на ноду в кластере,
все сервисы работающие с этим кластером должны быть способны прочитать новые данные.
Этого можно достичь двумя путями: либо сохранять новые данные сразу же на все ноды,
либо сохранять и считывать данные в режиме кворума, об этом я расскажу позже.</p><p>В примере выше, третий сервис обязательно прочитает самое последнее значение переменной равное <code>A=10</code>.</p><h3 id=слабая-weak-consistency>Слабая (Weak Consistency)</h3><p>Слабая модель предполагает, что после сохранения новых данных на ноду в кластере, данные могут обновляться на всех нодах кластера
в течении какого-то периода времени.
Некоторые ноды в кластере получат новые данные раньше, а некоторые позже, но в конечном итоге на всех нодах кластера появится эти новые данные.
Период с момента сохранения новых данных на одну ноду до появления этих данных на всех нодах кластера называется окном несогласованности (inconsistency window).</p><p>В примере выше, третий сервис может считать любое из трех значений переменной <code>A</code>: <code>0</code>, <code>5</code>, <code>10</code>.
Значение будет зависеть от того к какой ноде обратился сервис и сколько прошло времени с момента последнего обновления данных на этой ноде.</p><h2 id=типы-репликации-данных>Типы репликации данных</h2><p>Репликация - это процесс синхронизации данных между несколькими нодами распределенной системы в кластере.</p><p>Например, есть три ноды базы данных и на одну из нод кто-то записывает новые данные.
С помощью механизма репликации новые данные с этой ноды будут синхронизированы с двумя другими нодами.
В результате на всех трех нодах будут одинаковые данные.</p><p>Репликация может потребоваться для:</p><ol><li>Бекапа, если что то случится с одной из нод, то останется еще несколько копии данных.</li><li>Отказоустойчивости, то же самое что и в пункте 1, если одна из нод выйдет из стоя, то останется еще несколько нод.</li><li>Распределения нагрузки, при большом количестве запросов, эти запросы можно равномерно распределить между несколькими нодами.</li></ol><p>Я приведу два основных типа репликации данных. Иногда встречаются вариации этих двух типов в зависимости от возможностей конкретной базы данных.</p><h3 id=master-slave>master-slave</h3><p>При <code>master-slave</code> репликации, есть одна главная нода - <code>master</code>, которая обрабатывает запросы на запись и чтение данных.
К главной ноде подключены еще <code>N</code> нод - <code>slave</code>, которые являются полными копиями <code>master</code> ноды.
В большинстве конфигураций на <code>slave</code>-ноду нельзя записать данные, эти ноды обрабатывают только запросы на чтение.
После добавления новых данных <code>master</code>-ноду данные реплицируются на все <code>slave</code>-ноды.</p><p>Если <code>master</code>-нода выходит из строя, то выбирается новая <code>master</code>-нода из <code>slave</code>-нод.
После чего, все запросы на запись идут в новую <code>master</code>-ноду.
Иногда процесс выбора новой главной ноды выполняется вручную, через изменение конфигурации,
а иногда автоматически. Временами имеется возможность восстановить вышедшую из строя <code>master</code>-ноду.</p><p>Во время смены <code>master</code>-ноды существует риск потерять данные.
Например, клиент что-то записал на <code>master</code>-ноду, после чего <code>master</code>-нода упала и данные не успели реплицироваться на <code>slave</code>-ноды.
Теперь после выбора новой <code>master</code>-ноды из живых <code>slave</code>-нод, те данные потеряются.</p><h3 id=multi-master-одноранговая-master-master-p2p>multi-master (одноранговая, master-master, P2P)</h3><p>При <code>multi-master</code> репликации все ноды являются <code>master</code>-нодами и все они главные.
Каждая нода умеет обрабатывать запросы на запись и на чтение.
После записи данных на одну <code>master</code>-ноду, данные реплицируются на остальные <code>master</code>-ноды.</p><p>Если выйдет из стоя одна <code>master</code>-нода, то оставшиеся <code>master</code>-ноды продолжат обрабатывать запросы.</p><h3 id=синхронная-и-асинхронная-репликация-данных>Синхронная и Асинхронная репликация данных</h3><p>Данные между нодами могут реплицироваться двумя способами - синхронно и асинхронно.</p><p>Синхронная репликация выглядит так:</p><ol><li>Клиент устанавливает соединение с <code>master</code>-нодой и присылает ей новые данные.</li><li><code>master</code>-нода сохраняет новые данные к себе и синхронно отправляет эти данные в другие ноды.</li><li>Все остальные ноды сохраняют новые данные к себе и сообщают <code>master</code>-ноде, что сохранение прошло успешно.</li><li><code>master</code>-нода, сообщает клиенту что сохранение новых данных прошло успешно и разрывает с ним соединение.</li></ol><p>В случае синхронной репликации, запрос на сохранение данных для клиента занимает достаточно долгое время.
Клиент должен дождаться, когда все ноды сохранят данные, только после этого клиент получит ответ об успешном сохранении.</p><p>Асинхронная репликация выглядит так:</p><ol><li>Клиент устанавливает соединение с <code>master</code>-нодой и присылает ей новые данные.</li><li><code>master</code>-нода сохраняет данные к себе, затем сообщает клиенту, что сохранение данных прошло успешно и разрывает соединение с клиентом.</li><li>Затем в фоне все остальные ноды забирают у <code>master</code>-ноды данные и сохраняют их к себе.</li></ol><p>В случае асинхронной репликации, запрос на сохранение данных для клиента занимает меньше времени,
потому что клиент не ждет сохранения данных на все ноды.
Но за повышение скорости сохранения взимается плата в виде ослабления модели согласованности данных и увеличения риска потери данных.</p><h3 id=кворум>Кворум</h3><p>Кворум используется при репликации <code>multi-master</code>, когда:</p><ul><li>необходимо повысить надежность сохранения данных</li><li>необходимо получить строгую модель согласованности данных</li></ul><p>Кворум - это режим записи данных сразу на несколько нод и чтения данных, сразу с нескольких нод.</p><p>Количество нод входящих в кворум считается по формуле <code>(n/2 + 1)</code>.
Например, при <code>5</code>-ти нодах запись и чтение будет выполняться на <code>3</code> ноды сразу.</p><p>Кворум позволяет повысить надежность записи данных, потому что данные будут записаны сразу на несколько нод,
а вероятность выхода из строя сразу нескольких нод минимальна.
Но иногда, из строя может выйти целый дата-центр.
Если требуется очень большая устойчивость к сбоям, но разные ноды одной БД располагают сразу в нескольких дата центрах.
В случае наличия нескольких дата центов, данные сохраняются сразу в несколько <code>master</code>-нод в разных дата центрах.</p><p>При чтение данных в режиме кворума запрос на чтение отправляется сразу на несколько нод,
результаты чтения сортируются по версиям и данные с самой последней версией отдаются клиенту.
Это гарантирует, что клиент всегда получит самую последнюю версию данных и позволяет добиться строгой модели согласованности данных.</p><p>Есть еще более гибкий подход - задавать количество нод, на которое требуется записать данные и с которых необходимо считать данные.
Что бы достичь строгой согласованности, следует придерживаться формулы <code>W + R > N</code>,
где <code>W</code> - количество нод на которые выполняется запись,
<code>R</code> - количество нод с которых выполняется чтение,
<code>N</code> - количество реплик с данными (replication factor).
Достаточно надежным считается количество реплик <code>N=3</code> и выше.</p><p>Например, есть три реплики <code>N=3</code>, у сервиса мало запросов на запись, но много запросов на чтение.
Тогда для достижения строгой согласованности эффективнее писать на <code>W=3</code> ноды, а считывать с <code>R=1</code> нод.
Условие <code>3 + 1 > 3</code> выполняется, сервис получает строгую согласованность данных и требуемую скорость чтения.</p><h2 id=cap>CAP</h2><p>CAP теорема описывает компромиссы при разработке и использовании распределенных систем.
Она применяется для базы данных, либо для распределенных файловых системы или хранилищ объектов вроде S3, HDFS.</p><p>Три буквы в слове CAP, являются свойствами распределенной системы: Consistency, Availability, Partition tolerance.
Теорема гласит, что возможно выбрать только два из трех свойств. Следовательно, необходимо пожертвовать одним из свойств.
Каким свойством жертвовать, зависит от требований к конкретной распределенной системе.</p><p>Разберем, что означает каждое свойство из CAP теоремы.</p><h3 id=consistency-согласованность>Consistency (Согласованность)</h3><p>Под согласованностью в CAP теореме понимается строгая модель согласованности данных.
Следовательно, клиент всегда должен видеть самую последнюю и свежую версию данных.</p><p>Как я уже писал выше, строгой модели согласованности можно добиться двумя путями:</p><ol><li>Использовать синхронную репликацию.</li><li>Использовать асинхронную репликацию с записью и чтением данных в режиме кворума.</li></ol><h3 id=availability-доступность>Availability (Доступность)</h3><p>Под доступностью в CAP теореме понимается, что если нода в рабочем состоянии, то она должна успешно отвечать на любой запрос.</p><p>Свойство доступности в CAP не учитывается лейтенси (<a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>),
что является одним из недостатков CAP.
Например, если нода отвечала на запрос 10 минут, то с точки зрения доступности в CAP это нормально и нода считается доступной.
В реальных системах такое большое лейтенси является проблемой и нода считается недоступной.</p><p>Поэтому следует сделать допущение и считать, что нода считается доступной, если она отвечает на запрос за разумный период времени, например за 200мс.
Это допущение противоречит оригинальной CAP теореме, но большинство делает его, потому что оно ближе к действительности.</p><h3 id=partition-tolerance-устойчивость-к-разделению>Partition tolerance (Устойчивость к разделению)</h3><p>Под устойчивостью к разделению в CAP теореме понимаются проблемы с сетью.
Это могут быть задержки, потери пакетов или полный разрыв соединения (<a href=https://en.wikipedia.org/wiki/Split-brain_(computing)>split-brain</a>)
в результате которого ноды не видят друг друга.</p><p>Распределенная система, состоящая из нескольких нод подразумевает, что она имеет дело с сетью.
Следовательно, нельзя пожертвовать этим свойством CAP теоремы,
неустойчивая к сетевым проблемам распределенная система работает некорректно.</p><h2 id=комбинации-cap-свойств>Комбинации CAP свойств</h2><p>CAP теорема гласит, что возможно выбрать только два из трех выше описанных свойств.
В результате получаются три комбинации: CP, AP, CA.
Разберем основные свойства каждой из этих комбинаций.</p><h3 id=cp-выбираем-consistency-и-partition-tolerance-жертвуем-availability>CP: Выбираем Consistency и Partition tolerance, жертвуем Availability</h3><p>Распределенная система устойчива к сетевым проблемам и соответствует строгой модели согласованности,
но при проблемах с сетью часть системы становится недоступной.</p><p>Например, при <code>master-slave</code> репликации одна из <code>slave</code>-нод может стать недоступной для чтения,
но <code>master</code>-нода продолжит принимать запросы на запись и чтение.
А вот если <code>master</code>-нода выйдет из строя, то БД будет недоступна для записи, но <code>slave</code>-ноды продолжат обрабатывать запросы на чтение.</p><p>Еще можно привести пример с двумя дата центрами.
Допустим есть два дата центра в разных регионах страны. Если в какой то момент соединение между ними теряется,
то второй дата центр должен перестать принимать запросы на чтение и запись,
а приложения работавшие со вторым дата центром, должны переключиться на первый рабочий дата центр.</p><h3 id=ap-выбираем-availability-и-partition-tolerance-жертвуем-consistency>AP: Выбираем Availability и Partition tolerance, жертвуем Consistency</h3><p>Распределенная система устойчива к сетевым проблемам и всегда доступна, но использует слабую модель согласованности.
При сетевых проблемах разные ноды будут выдавать разные данные на один и тот же запрос из-за отсутствия репликации между ними.</p><p>Например, при <code>multi-master</code> конфигурации во время потери связи между нодами (split-brain) репликация остановится,
но ноды продолжат работать независимо, хоть и не будут знать об новых данных друг у друга.</p><p>Или например, при <code>master-slave</code> конфигурации во время потери связанности с <code>master</code>-нодой <code>slave</code>-ноды продолжат выполнять запросы на чтение,
но они будут отдавать только старые данные.</p><p>В примере с двумя дата центрами, когда между ними происходит разрыв соединения, оба дата центра становятся на время независимыми и
не видят обновления друг у друга, в результате чего часть данных в них устаревает до момента возобновления соединения.</p><h3 id=ca-выбираем-consistency-и-availability-жертвуем-partition-tolerance>CA: Выбираем Consistency и Availability, жертвуем Partition tolerance</h3><p>Как я уже писал выше в распределенной системе нельзя пожертвовать <code>Partition tolerance</code>, потому что распределенная система всегда имеет дело с сетью.
К этой категории возможно &ldquo;с натяжкой&rdquo; отнести базы данных работающие в режиме одной нодой на одном сервере без репликации данных.</p><h2 id=типы-баз-данных>Типы баз данных</h2><p>Рассмотрим популярные типы баз данных с точки зрения CAP теоремы.</p><h3 id=реляционные-базы-данных-relational-database-rdbm>Реляционные базы данных (Relational Database, RDBM)</h3><p>Реляционные БД один из самых старших и зрелых видов БД, они являются одними их самых гибких в настройке.
Большинство из популярных баз поддерживают как <code>master-slave</code>, так и <code>multi-master</code> репликацию, синхронную и асинхронную.
Базу возможно сконфигурировать как со строгой согласованностью данных так и со слабой.</p><p>Реляционные БД могут попадать в категорию CP, либо AP по CAP в зависимости от типа репликации данных и настроек.</p><h3 id=документные-базы-данных-document-oriented-database>Документные базы данных (Document-oriented database)</h3><p>Типичный представитель этого типа баз данных - MongoDB.
Она поддерживает только асинхронную <code>master-slave</code> репликацию данных.
В конфигурации по умолчанию чтение и запись выполняется через <code>master</code>-ноду, БД поддерживает строгую согласованность данных и является CP по CAP.</p><p>При отказе <code>master</code>-ноды, будет автоматически выбрана новая <code>master</code>-нода, но на новой ноде может не оказаться новых данных из-за асинхронной репликации.
Поэтому при автоматическом выборе новой <code>master</code>-ноды MongoDB гарантирует только слабую согласованность.</p><p>В MongoDB возможно сконфигурировать чтение с <code>slave</code>-нод и уровень согласованности данных при репликации между <code>master</code> и <code>slave</code>.
Благодаря этим настройкам возможно добиться нужного уровня согласованности данных при чтении с <code>slave</code>-нод и достичь либо CP, либо AP по CAP.</p><p>Делаем вывод, что в зависимости от конфигурации MongoDB следует рассматривать как CP, либо как AP по CAP.</p><h3 id=column-family-databases>Column-family databases</h3><p>Прародитель этого типа баз данных - <a href=https://static.googleusercontent.com/media/research.google.com/ru//archive/bigtable-osdi06.pdf>Google BigTable</a>.</p><p>Наиболее популярным open source представителем этой категории баз данных является Cassandra, о ней и поговорим.
Cassandra с самого начала создавалась как распределенная база данных для высоконагруженных систем с упором на масштабируемость.</p><p>Эта БД поддерживает только асинхронную <code>multi-master</code> репликацию данных.
Для каждого запроса требуется задать <a href=https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html>уровень согласованности</a>.
Если указать значение меньшее чем количество нод в кворуме, то получится слабая согласованность данных,
а если указать кворум, то получится строгая согласованность данных.</p><p>Из этого можно сделать вывод, что в зависимости от запроса эта БД может относится как к CP, так и к AP типу по CAP теореме.
Благодаря возможности задать уровень согласованности прямо в запросе, некоторые запросы могут быть CP типа, а некоторые AP типа.</p><h2 id=компромиссы-cap-теоремы>Компромиссы CAP теоремы</h2><p>Большинство баз данных можно настроить как БД CP типа, так и AP типа по CAP.
Базы предоставляют гибкую конфигурацию модели согласованности данных,
поэтому сложно отнести какую либо БД к одному конкретному типу по CAP.</p><p>CAP теорема обладает большим количеством недостатков, например:</p><ul><li>в <code>Availability</code> ничего не сказано про лейтенси (<a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>)</li><li>под <code>Consistency</code> понимается только строгая модель согласованности данных</li><li>CAP теорема не учитывает транзакции</li></ul><p>Подробнее про недостатки CAP теоремы можно почитать в статье <a href=https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html>Please stop calling databases CP or AP</a> (<a href=https://habr.com/ru/post/258145/>Перевод на русский</a>).</p><p>Не стоит считать CAP теорему истиной в последней инстанции.
К CAP следует относится как к формальной теореме для приблизительного понимания компромиссов существующих в распределенных системах.
Из-за большого количества недостатков распределение БД по CAP очень условное, т.к.
БД имеют гибкие настройки согласованности данных, которые сложно учесть при соотнесении их с CAP теоремой.</p><p>CAP теорему следует использовать только при поверхностном описании распределенной системы,
что бы слушатель/читатель мог примерно понять каких свойств по доступности и согласованности данных вы пытаетесь достичь.</p><p>Более точным подходом будет выбор между строгостью модели согласованности данных и получаемым в результате лейтенси.
Чем выше согласованность данных, тем больше времени нужно на выполнение запросов и следовательно тем выше будет лейтенси.
И наоборот, при слабой согласованности запросы выполняются быстрее и лейтенси уменьшается.
Смещение в ту или иную сторону зависит конкретной предметной области и требований к системе.</p><h2 id=дальнейшее-чтение>Дальнейшее чтение</h2><ul><li><a href=https://www.amazon.com/gp/product/0321826620>NoSQL Distilled Book</a></li><li><a href=http://dbmsmusings.blogspot.com/2019/07/overview-of-consistency-levels-in.html>Overview of Consistency Levels in Database Systems</a></li><li><a href=https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html>Please stop calling databases CP or AP</a> (<a href=https://habr.com/ru/post/258145/>Перевод на русский</a>)</li><li><a href=https://en.wikipedia.org/wiki/Consistency_model>Consistency model Wikipedia</a></li><li><a href=https://blog.jetbrains.com/blog/2021/06/03/big-data-world-part-5-cap-theorem/>Big Data World, Part 5: CAP Theorem</a></li><li><a href=https://habr.com/ru/post/322276/>Мифы о CAP теореме</a></li></ul></article><ul class="pager blog-pager"><li class=previous><a href=https://jaitl.pro/russian/2021/08/04/coroutines/ data-toggle=tooltip data-placement=top title="Генераторы, Асинхронность, Корутины">&larr; Previous Post</a></li><li class=next><a href=https://jaitl.pro/russian/2022/12/26/spring-data-jpa-batch/ data-toggle=tooltip data-placement=top title="Батчевое сохранение данных в Spring Data JPA">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href=https://github.com/jaitl title=GitHub><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a href=https://twitter.com/jaitl title=Twitter><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-twitter fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted"><a href=https://jaitl.pro>Jaitl</a>
&nbsp;&bull;&nbsp;&copy;
2023
&nbsp;&bull;&nbsp;
<a href=https://jaitl.pro>Jaitl's blog</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.111.3</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://jaitl.pro/js/katex.min.js></script>
<script src=https://jaitl.pro/js/auto-render.min.js></script>
<script src=https://jaitl.pro/js/jquery-3.5.1.slim.min.js></script>
<script src=https://jaitl.pro/js/bootstrap.min.js></script>
<script src=https://jaitl.pro/js/main.js></script><script>renderMathInElement(document.body)</script><script src=https://jaitl.pro/js/photoswipe.min.js></script>
<script src=https://jaitl.pro/js/photoswipe-ui-default.min.js></script><script src=https://jaitl.pro/js/load-photoswipe.js></script></body></html>